{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c477fd72",
   "metadata": {},
   "source": [
    "# Basic Approach\n",
    "\n",
    "A basic approach to find the k most frequent words is to create a hash map. Since the data can be large, it will be processed in chunks.\n",
    "First a set of stop words is created from a file containing the stop words. Then the data will be read in chunks. Every word will be checked if it is in the stop words set. If it is not, it will increase the count of the word in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82981428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_frequent_words(dataset, stop_words_file, k):\n",
    "    word_freq = {}\n",
    "\n",
    "    with open(stop_words_file, 'r') as stop_words:\n",
    "        stop_word_set = set(stop_words.read().splitlines())\n",
    "        stop_word_set.add('-')\n",
    "        stop_word_set.add('–')\n",
    "    words = dataset.lower().split()\n",
    "\n",
    "    for word in words:\n",
    "        if word not in stop_word_set:\n",
    "            if word in word_freq:\n",
    "                word_freq[word] += 1\n",
    "            else:\n",
    "                word_freq[word] = 1\n",
    "\n",
    "    return word_freq\n",
    "\n",
    "chunk_size = 1024 * 1024 * 1024\n",
    "stop_words_file = '../dataset/stopwords'\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "446726c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('would', 21935), ('us', 18242), ('economic', 15389), ('new', 15365), ('one', 14078), ('countries', 13501), ('political', 12547), ('even', 12466), ('also', 12051), ('global', 11783)]\n",
      "CPU times: user 1.91 s, sys: 88.9 ms, total: 1.99 s\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_freq = {}\n",
    "\n",
    "with open('../dataset/small_50MB_dataset.txt', 'r') as file:\n",
    "    while True:\n",
    "        chunk = file.readlines(chunk_size)\n",
    "        if not chunk:\n",
    "            break\n",
    "\n",
    "        chunk_word_freq = top_k_frequent_words(' '.join(chunk), stop_words_file, k)\n",
    "\n",
    "        for word, count in chunk_word_freq.items():\n",
    "            if word in word_freq:\n",
    "                word_freq[word] += count\n",
    "            else:\n",
    "                word_freq[word] = count\n",
    "\n",
    "sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "top_k_words = sorted_words[:10]\n",
    "print(top_k_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dbea6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('european', 316722), ('mr', 210160), ('would', 179735), ('also', 175907), ('must', 153791), ('commission', 138407), ('president,', 125700), ('member', 124360), ('like', 108992), ('one', 94368)]\n",
      "CPU times: user 12.1 s, sys: 2.2 s, total: 14.2 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_freq = {}\n",
    "\n",
    "with open('../dataset/data_300MB.txt', 'r') as file:\n",
    "    while True:\n",
    "        chunk = file.readlines(chunk_size)\n",
    "        if not chunk:\n",
    "            break\n",
    "\n",
    "        chunk_word_freq = top_k_frequent_words(' '.join(chunk), stop_words_file, k)\n",
    "\n",
    "        for word, count in chunk_word_freq.items():\n",
    "            if word in word_freq:\n",
    "                word_freq[word] += count\n",
    "            else:\n",
    "                word_freq[word] = count\n",
    "\n",
    "sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "top_k_words = sorted_words[:10]\n",
    "print(top_k_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef1ba9",
   "metadata": {},
   "source": [
    "# Multi-processing\n",
    "\n",
    "To make it faster, multi-processing is applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d0807bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import collections\n",
    "\n",
    "def process_chunk(chunk, stop_words):\n",
    "    word_freq = collections.defaultdict(int)\n",
    "    for line in chunk:\n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "            if word.lower() not in stop_words:\n",
    "                word_freq[word] += 1\n",
    "    return word_freq\n",
    "\n",
    "def get_k_most_frequent_words(file_path, stop_words_file, k, num_threads):\n",
    "    chunk_size = 1024 * 1024 * 1024  # 1GB\n",
    "    word_freq = collections.defaultdict(int)\n",
    "\n",
    "    # Read stop words from file\n",
    "    with open(stop_words_file, 'r') as stop_words_file:\n",
    "        stop_words = set(stop_words_file.read().split())\n",
    "        stop_words.add('-')\n",
    "        stop_words.add('–')\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "            futures = []\n",
    "            while True:\n",
    "                chunk = file.readlines(chunk_size)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                future = executor.submit(process_chunk, chunk, stop_words)\n",
    "                futures.append(future)\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                chunk_freq = future.result()\n",
    "                for word, count in chunk_freq.items():\n",
    "                    word_freq[word] += count\n",
    "\n",
    "    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_words[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e526536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "\n",
    "def get_k_most(filepath, k, n):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    top_words = get_k_most_frequent_words(file_path, 'dataset/stopwords', k, n)\n",
    "    for word, count in top_words:\n",
    "        print(f'{word},{count}')\n",
    "    \n",
    "    print('\\n')\n",
    "    end_time = time.time()\n",
    "    running_time = end_time - start_time\n",
    "    print(f\"Running Time: {round(running_time,2)} seconds\")\n",
    "    \n",
    "    cpu_utilization = psutil.cpu_percent()\n",
    "    print(f\"CPU Utilization: {cpu_utilization}%\")\n",
    "    \n",
    "    memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # in MB\n",
    "    print(f\"Memory Usage: {memory_usage} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f90728",
   "metadata": {},
   "source": [
    "The get_k_most function now takes three arguments. The first is the data file, the second is how many words one wants to see in the result, and the third is the number of threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b40af9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would,21795\n",
      "US,15810\n",
      "economic,14464\n",
      "countries,13136\n",
      "new,12460\n",
      "political,12229\n",
      "also,12018\n",
      "one,11708\n",
      "global,10935\n",
      "European,10824\n",
      "\n",
      "\n",
      "Running Time: 1.81 seconds\n",
      "CPU Utilization: 7.8%\n",
      "Memory Usage: 539.68359375 MB\n"
     ]
    }
   ],
   "source": [
    "file_path = 'dataset/small_50MB_dataset.txt'\n",
    "get_k_most(file_path, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "932cb2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would,21795\n",
      "US,15810\n",
      "economic,14464\n",
      "countries,13136\n",
      "new,12460\n",
      "political,12229\n",
      "also,12018\n",
      "one,11708\n",
      "global,10935\n",
      "European,10824\n",
      "\n",
      "\n",
      "Running Time: 1.76 seconds\n",
      "CPU Utilization: 9.8%\n",
      "Memory Usage: 541.20703125 MB\n"
     ]
    }
   ],
   "source": [
    "get_k_most(file_path, 10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "480dbd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European,316713\n",
      "Mr,210158\n",
      "would,178550\n",
      "also,175427\n",
      "must,153717\n",
      "Commission,138001\n",
      "President,,125489\n",
      "Member,119742\n",
      "like,107437\n",
      "Parliament,85550\n",
      "\n",
      "\n",
      "Running Time: 11.4 seconds\n",
      "CPU Utilization: 13.2%\n",
      "Memory Usage: 774.92578125 MB\n"
     ]
    }
   ],
   "source": [
    "file_path = 'dataset/data_300MB.txt'\n",
    "get_k_most(file_path, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7ed90a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European,316713\n",
      "Mr,210158\n",
      "would,178550\n",
      "also,175427\n",
      "must,153717\n",
      "Commission,138001\n",
      "President,,125489\n",
      "Member,119742\n",
      "like,107437\n",
      "Parliament,85550\n",
      "\n",
      "\n",
      "Running Time: 11.12 seconds\n",
      "CPU Utilization: 11.8%\n",
      "Memory Usage: 905.2265625 MB\n"
     ]
    }
   ],
   "source": [
    "file_path = 'dataset/data_300MB.txt'\n",
    "get_k_most(file_path, 10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b821249a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said,1572125\n",
      "would,903267\n",
      "one,755766\n",
      "said.,726275\n",
      "also,704422\n",
      "de,620092\n",
      "last,573309\n",
      "two,566546\n",
      "first,557474\n",
      "people,557166\n",
      "\n",
      "\n",
      "Running Time: 133.01 seconds\n",
      "CPU Utilization: 27.0%\n",
      "Memory Usage: 1955.5 MB\n"
     ]
    }
   ],
   "source": [
    "file_path = 'dataset/data_2.5GB.txt'\n",
    "get_k_most(file_path, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb4d4fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said,1572125\n",
      "would,903267\n",
      "one,755766\n",
      "said.,726275\n",
      "also,704422\n",
      "de,620092\n",
      "last,573309\n",
      "two,566546\n",
      "first,557474\n",
      "people,557166\n",
      "\n",
      "\n",
      "Running Time: 135.42 seconds\n",
      "CPU Utilization: 30.8%\n",
      "Memory Usage: 2477.74609375 MB\n"
     ]
    }
   ],
   "source": [
    "file_path = 'dataset/data_2.5GB.txt'\n",
    "get_k_most(file_path, 10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3644ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said,10397763\n",
      "would,5738120\n",
      "said.,4692632\n",
      "one,4664992\n",
      "also,4446636\n",
      "two,3535784\n",
      "last,3520997\n",
      "first,3458376\n",
      "people,3447034\n",
      "new,3377098\n",
      "\n",
      "\n",
      "Running Time: 819.04 seconds\n",
      "CPU Utilization: 22.7%\n",
      "Memory Usage: 3869.41015625 MB\n"
     ]
    }
   ],
   "source": [
    "file_path = 'dataset/data_16GB.txt'\n",
    "get_k_most(file_path, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18baadee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said,10397763\n",
      "would,5738120\n",
      "said.,4692632\n",
      "one,4664992\n",
      "also,4446636\n",
      "two,3535784\n",
      "last,3520997\n",
      "first,3458376\n",
      "people,3447034\n",
      "new,3377098\n",
      "\n",
      "\n",
      "Running Time: 789.34 seconds\n",
      "CPU Utilization: 17.9%\n",
      "Memory Usage: 3546.11328125 MB\n"
     ]
    }
   ],
   "source": [
    "file_path = 'dataset/data_16GB.txt'\n",
    "get_k_most(file_path, 10, 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
